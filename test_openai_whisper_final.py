#!/usr/bin/env python3
"""
Final verification that debabelizer's OpenAI Whisper provider works correctly
"""

import asyncio
import os
import sys
import tempfile
import wave
import numpy as np

# Add debabelizer to path
sys.path.append('/home/peter/debabelizer/src')

# Load environment variables
sys.path.append('backend')
from dotenv import load_dotenv
load_dotenv('backend/.env')

def create_speech_audio_file():
    """Create a more realistic speech audio file"""
    sample_rate = 16000
    duration = 3.0  # 3 seconds
    
    # Create a simple spoken phrase simulation
    t = np.linspace(0, duration, int(sample_rate * duration), False)
    
    # Simulate vowel sounds with formants
    # "Hello World" - simplified vowel formants
    hello_freq = [600, 1200, 2400]  # /e/ vowel formants  
    world_freq = [400, 800, 2600]   # /o/ vowel formants
    
    # Create segments
    seg1 = t < 1.5  # "Hello" 
    seg2 = t >= 1.5  # "World"
    
    wave = np.zeros_like(t)
    
    # Hello segment
    for freq in hello_freq:
        wave[seg1] += 0.2 * np.sin(2 * np.pi * freq * t[seg1])
    
    # World segment  
    for freq in world_freq:
        wave[seg2] += 0.2 * np.sin(2 * np.pi * freq * t[seg2])
    
    # Add envelope to make it more speech-like
    envelope = np.exp(-2 * (t - duration/2)**2 / duration**2)  # Gaussian envelope
    wave = wave * envelope
    
    # Add some amplitude modulation for speech rhythm
    modulation = 0.7 + 0.3 * np.sin(2 * np.pi * 4 * t)
    wave = wave * modulation
    
    # Convert to 16-bit PCM
    wave_int16 = (wave * 16000).astype(np.int16)
    
    return wave_int16, sample_rate

async def test_openai_whisper_comprehensive():
    """Comprehensive test of OpenAI Whisper provider"""
    print("üß™ Comprehensive OpenAI Whisper Provider Test")
    print("=" * 50)
    
    try:
        from debabelizer import VoiceProcessor
        print("‚úÖ Debabelizer imported")
        
        # Test 1: Provider initialization
        print("\n1Ô∏è‚É£ Testing provider initialization...")
        processor = VoiceProcessor(stt_provider="openai_whisper")
        print(f"‚úÖ Provider initialized: {processor.stt_provider_name}")
        
        # Test 2: Provider properties
        print("\n2Ô∏è‚É£ Testing provider properties...")
        provider = processor.stt_provider
        print(f"   Name: {provider.name}")
        print(f"   Supports streaming: {provider.supports_streaming}")
        print(f"   Supports language detection: {provider.supports_language_detection}")
        print(f"   Supported languages: {len(provider.supported_languages)}")
        
        # Test 3: Connection test
        print("\n3Ô∏è‚É£ Testing API connection...")
        connection_ok = await provider.test_connection()
        print(f"   Connection status: {'‚úÖ Connected' if connection_ok else '‚ùå Failed'}")
        
        # Test 4: Audio transcription
        print("\n4Ô∏è‚É£ Testing audio transcription...")
        audio_data, sample_rate = create_speech_audio_file()
        
        # Convert to bytes
        import struct
        audio_bytes = struct.pack(f'<{len(audio_data)}h', *audio_data)
        print(f"   Generated {len(audio_bytes)} bytes of speech-like audio")
        
        result = await processor.transcribe_audio(
            audio_data=audio_bytes,
            audio_format="wav",
            sample_rate=sample_rate,
            language="en"
        )
        
        print(f"   ‚úÖ Transcription: '{result.text}'")
        print(f"   Confidence: {result.confidence}")
        print(f"   Language: {result.language_detected}")
        print(f"   Processing time: {result.duration:.2f}s")
        
        # Test 5: File transcription
        print("\n5Ô∏è‚É£ Testing file transcription...")
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
            # Write WAV file
            with wave.open(tmp_file.name, 'wb') as wav_file:
                wav_file.setnchannels(1)
                wav_file.setsampwidth(2)
                wav_file.setframerate(sample_rate)
                wav_file.writeframes(audio_bytes)
            
            temp_path = tmp_file.name
        
        try:
            file_result = await processor.transcribe_file(temp_path, language="en")
            print(f"   ‚úÖ File transcription: '{file_result.text}'")
            print(f"   Confidence: {file_result.confidence}")
        finally:
            os.unlink(temp_path)
        
        # Test 6: Language auto-detection
        print("\n6Ô∏è‚É£ Testing language auto-detection...")
        auto_result = await processor.transcribe_audio(
            audio_data=audio_bytes,
            audio_format="wav",
            sample_rate=sample_rate,
            language=None  # Auto-detect
        )
        print(f"   ‚úÖ Auto-detected: '{auto_result.text}' (lang: {auto_result.language_detected})")
        
        # Test 7: Cost estimation
        print("\n7Ô∏è‚É£ Testing cost estimation...")
        cost = provider.get_cost_estimate(3.0)  # 3 seconds
        print(f"   ‚úÖ Estimated cost for 3s: ${cost:.4f}")
        
        # Test 8: Usage statistics
        print("\n8Ô∏è‚É£ Testing usage statistics...")
        stats = processor.get_usage_stats()
        print(f"   STT requests: {stats['stt_requests']}")
        print(f"   Total cost estimate: ${stats['cost_estimate']:.4f}")
        
        # Test 9: Error handling (streaming not supported)
        print("\n9Ô∏è‚É£ Testing error handling...")
        try:
            await provider.start_streaming()
            print("   ‚ùå Should have raised error for streaming")
        except Exception as e:
            print(f"   ‚úÖ Correctly raised error: {str(e)[:50]}...")
        
        # Cleanup
        await processor.cleanup()
        print("\n‚úÖ All tests completed successfully!")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(test_openai_whisper_comprehensive())
    
    print("\n" + "=" * 50)
    if success:
        print("üéâ OpenAI Whisper provider verification PASSED")
        print("üí° Provider is working correctly for file-based transcription")
        print("‚ö†Ô∏è  Note: Not suitable for real-time streaming in debabelize.me")
    else:
        print("üí• OpenAI Whisper provider verification FAILED")